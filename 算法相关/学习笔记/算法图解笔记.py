路线图
    基础：
        第 1 章：
            将学习第一种实用的算法 --> 二分查找
            还将学习使用 大O表示法 分析算法的速度
        第 2 章：
            学习两种基本的数据结构 --> 数组和链表
                它们贯穿全文并还将被用来创建更高级的数据结构 --> 散列表（第 5 章）
        第 3 章：
            学习递归，一种被众多算法（如第 4 章的快速排序）采用的实用技巧

    介绍应用广泛的算法（余下章节）
        问题解决技巧：
            遇到问题，如果不确定该如何高效地解决，可以尝试 --> 分而治之（第 4 章）或 动态规划（第 9 章）
            如果认识到根本就没有高效的解决方案，可转而使用贪婪算法（第 8 章）来得到近似答案

        散列表（第 5 章）：
            散列表是一种很有用的数据结构，由键值对组成，如 人名和电子邮箱地址 或 用户名和密码
                散列表的用途非常的大，每当我需要解决问题时，首先想到的两种方法是：
                    可以使用散列表吗？
                    可以使用图来建立模型吗？

        图算法（第 6、7 章）：
            图是一种模拟网络的方法，这种网络包括人际关系网、公路网、神经元网络或者任何一组连接。
            广度优先搜索（第 6 章）和狄克斯特拉算法（第 7 章）计算网络中两点之间的最短距离，可用来计算两人之间的分隔度或前往目的地的最短路径

        K最近邻算法（KNN）（第 10 章）：
            这是一种简单的机器学习算法，可用于创建推荐系统、OCR引擎、预测股价或其他值（如“我们认为Adit会给这部电影打4星”）的系统，以及对物件进行分类（如“这个字母是 Q”）

        适合你进一步学习的 10 种算法（第 11 章）：


第 1 章（算法简介）：
    1、算法 是一组完成任务的指令。任何代码片段都可视为算法。
        性能：
            明白使用的算法的优缺点

    2、对数：
        log 不写底数时默认的底数可能是 2、e 或 10。具体情况要以文章明确给出的记号表或案例说明为准。
        通常情况下，数学计算中都是 10，计算机学科是 2，编程语言里面是 e。

    3、简单查找：
        运行时间：
            O(n)
        代码示例：
            def simple_search(list, item):
                for index in range(len(list)):
                    if list[index] == item:
                        return index
                else:
                    return None

    4、二分查找：
        条件：一个有序的元素列表
            每次排除一半的单词，直至最后只剩下一个单词或者返回 None
        运行时间：
            O(log n)
        代码示例：
            def binary_search(list, item):
                low = 0
                high = len(list) - 1

                while low <= high:
                    mid = (low + high) // 2
                    guess = list[mid]

                    if guess == item:
                        return mid
                    if guess > item:
                        high = mid - 1
                    else:
                        low = mid + 1

                return None

    5、运行时间
        每次介绍算法，都要讨论其运行时间。一般而言，应该选择效率最高的算法，以最大限度地减少运行时间或占用空间。
            线性时间
                最多需要猜测的次数与列表长度相同 --> O(n)
            对数时间
                二分查找的运行时间为对数时间（或 log时间） --> O(log n)

    6、大 O 表示法
        大 O 表示法是一种特殊的表示法，指出了算法的速度有多快。
        1、算法的运行时间以不同的速度增加
            仅知道算法需要多长时间才能运行完毕还不够，还需要知道运行时间如何随列表增长而增加。这正是 大O表示法 的用武之地。
            大 O 表示法指的并非以秒为单位的速度。大 O 表示法让你能够比较操作数，它指出了算法运行时间的增速。
        2、大 O 表示法指出了最糟糕情况下的运行时间

        常见的 大 O 运行时间
            O( 1 )              常量时间
            O(log n)            对数时间：包括：二分查找
            O(n)                线性时间：包括：简单查找
            O(n * log n)        包括：快速排序
            O(n ^ 2)            包括：选择排序
            O(n!)

    7、小结：
        1）二分查找的速度比简单查找快得多
        2）O(log n) 比 O(n) 快，当需要搜索的元素越多时，前者比后者快得越多
        3）算法的运行时间并不以秒为单位，算法运行时间是从其增速的角度度量的
        4）算法的运行时间用 大 O 表示法 表示
        5）算法的速度指的并非时间，而是操作数的增速
        6）讨论算法的速度是，我们说的是随着输入的增加，其运行时间将以什么样的速度增加


第 2 章（选择排序）：
    1、内存的工作原理：
        需要将数据存储到内存时，你请求计算机提供存储空间，计算机给你一个存储地址（内存地址）。
        存储多项数据的两种基本方式（两种最基本的数据结构）
            数组
                优点：读取元素时，可以随机直接读取某一个元素（跳跃读取）
                缺点：没有足够的连续的空闲存储空间时，则不能存储；如果预留位置，那么可能会浪费内存 或 超出时又要移动
                支持随机访问和顺序访问
            链表
                优势：随机插入元素（存入内存，将其内存地址存储到前一个元素中）
                缺点：读取元素时，需要先读取前面的元素再一个个递进到需要的元素
                只支持顺序访问

    2、学习一种排序算法：
        很多算法仅在数据经过排序之后才管用，如：
            二分查找

        选择排序：
            从小到大的顺序排列：
                遍历整个列表，将最小值添加到一个新的列表中
                再次按照这种方法，找出第二小的数值
                依次这样查找，直到列表的所有值都添加到了新的列表中
            运行时间：
                O( n * n ) = O( n^2 )
            代码示例：
                def findSmallest(arr):
                    smallest = arr[0]
                    smallest_index = 0

                    for i in range(1, len(arr)):
                        if arr[i] < smallest:
                            smallest = arr[i]
                            smallest_index = i

                    return smallest_index

                def selectionSort(arr):
                    newArr = []
                    for i in range(len(arr)):
                        smallest = findSmallest(arr)
                        newArr.append(arr.pop(smallest))

                    return newArr

    3、小结：
        1）计算机内存犹如一大堆抽屉
        2）需要存储多个元素时，可使用数组或链表
        3）数组的元素都在一起
        4）链表的元素时分开的，其中每个元素都存储了下一个元素的地址
        5）数组的读取速度很快
        6）链表的插入和删除速度很快
        7）在同一个数组中，所有元素的类型都必须相同（都为 int、double 等），这样才能比较大小


第 3 章（递归）：
    1、递归：
        递归是很多算法都使用的一种编程方法，递归只是让解决方案更清晰，并没有性能上的优势
        编写递归函数时，为了告诉它何时终止，避免无限循环，因此每个递归函数都有两部分：
            基线条件（终止条件）
            递归条件（函数调用自己）

    2、栈：
        后进先出
        调用栈：
            计算机在内部使用被称为 调用栈 的栈。
        递归调用栈

    3、小结：
        1）递归指的是调用自己的函数
        2）每个递归函数都有两个条件：基线条件和递归条件
        3）栈有两种操作：压入和弹出
        4）所有函数调用都进入调用栈
        5）调用栈可能很长，这将占用大量的内存
            解决方法：
                a、重新编写代码，转而使用循环
                b、使用尾递归（并非所有的语言都支持尾递归）


第 4 章（快速排序）：
    使用上一章学到的新技能来解决问题
        1、分而治之（divide and conquer，D&C）
            一种著名的递归式问题解决方法、一种解决问题的思路。

            D&C 策略，D&C算法是递归的。使用 D&C 解决问题的过程包含两个步骤：
                1、找出简单的基线条件
                2、不断将问题分解（或者说缩小规模），直到符合基线条件

        2、快速排序：
            一种使用 D&C 的排序算法
            工作原理：
                1、从数组中选择一个元素，这个元素被称为基准值
                2、（分区）将数组分成两个子数组：根据基准值，找出比基准值小的元素以及比基准值大的元素：
                    a、一个由所有小于基准值的数字组成的子数组
                    b、基准值
                    c、一个由所有大于基准值的数字组成的子数组
                3、对这两个子数组进行快速排序
            归纳证明：
                基线条件
                归纳条件
            代码示例：
                def quicksort(array):
                    if len(array) < 2:
                        return array
                    else:
                        pivot = array[0]
                        less = [i for i in array[1:] if i <= pivot]
                        greater = [i for i in array[1:] if i > pivot]

                        return quicksort(less) + [pivot] + quicksort(greater)

        3、小结：
            1）D&C 将问题逐步分解。使用 D&C 处理列表时，基线条件很可能是空数组或只包含一个元素的数组
            2）实现快速排序时，请随机的选择用做基准值的元素。快速排序的平均运行时间为 O(n * log n)
            3）大 O 表示法中的常量有时候事关重大，这就是快速排序比合并排序快的原因所在
            4）比较简单查找和二分查找时，常量几乎无关紧要，因为列表很长时，O(log n) 的速度比 O(n) 快得多


第 5 章（散列表）：
    散列表也被称为：散列映射、映射、字典和关联数组
        散列函数和数组创建了一种被称为散列表的数据结构。
            散列表是一种包含额外逻辑的数据结构，数组和链表都被直接映射到内存，但散列表更复杂，它使用散列函数来确定元素的存储位置。
            用于创建散列表的散列函数根据字符串生成数组索引

    散列表的内部机制：
        散列函数
        实现
            大多数语言都提供了散列表实现
        冲突 and 性能
            避免冲突
                较低的填装因子
                良好的散列函数

    散列表是无序的，添加键-值对的顺序无关紧要
        为什么是无序的？
            散列表由散列函数和数组组成，由于其内部的原理，为了避免冲突进而提高性能（查找、插入和删除的速度）
                较低的填装因子
                良好的散列函数
                    良好的散列函数让数组中的值呈均匀分布

    可能根本不需要自己去实现散列表，任一优秀的语言都提供了散列表实现
        Python 提供的散列表实现为字典：（字典 book 也可称为散列表，散列表由键和值组成，并将键映射到值）
            >>> book = dict()
            >>> book['apple'] = 0.67
            >>> book['milk'] = 1.49
            >>> book['avocado'] = 1.49
            >>> print book
            {'apple': 1.49, 'apple': 0.67, 'milk': 1.49}

            >>> print book['avocado']
            1.49

    散列表适合用于：
        模拟映射关系（用于查找）
        防止重复
        缓存/记住数据，以免服务器再通过处理来生成它们

    小结：
        散列表是一种功能强大的数据结构，其操作速度快，还能让你以不同的方式建立数据模型。
        你可以结合散列函数和数组来创建散列表。
        冲突很糟糕，你应使用可以最大限度减少冲突的散列函数。
        散列表的查找、插入和删除速度都非常快。
        散列表适合用于模拟映射关系。
        一旦填装因子超过 0.7，就该调整散列表的长度。
        散列表可用于缓存数据（例如，在 Web 服务器上）。
        散列表非常适合用于防止重复。
        目前已经讲到的数据结构（数组、链表、栈--不能用于查找、散列表）。


第 6 章（广度优先搜索）：
    从 A 到 B 的最短路径，这种问题被称为 “最短路径问题”
    解决“最短路径问题”的算法被称为 “广度优先搜索”

    确定从 A地 到 B地，需要两个步骤：
        （1）使用图来建立问题模型
        （2）使用“广度优先搜索”解决问题

    图是什么？
        图模拟一组连接，图用于模拟不同的东西是如何相连的。
        图由节点和边组成：
            一个节点可能与众多节点直接相连，这些节点被称为邻居
             ------      边       ------
            | 节点 |   ------>   | 节点 |
             ------               ------

             有向图（关系是单向的）
             无向图（关系是双向的）

        树：
            树是一种特殊的图，树是图的子集，因此树都是图，但图可能是树，也可能不是。

    广度优先搜索
        广度优先搜索是一种用于图的查找算法；二分查找也是一种查找算法，不过只能在有序的元素列表中查找元素
        广度优先搜索可帮助回答两类问题：
            第一类问题：从节点A出发，有前往节点B的路径吗？
            第二类问题：从节点A出发，前往节点B的哪条路径最短？

        队列：先进先出 的数据结构
        栈：后进先出 的数据结构

    代码示例：
        图：
            # 图的结构
            # graph = {
            #     'you': ['alice', 'bob', 'claire'],
            #     'alice': ['anuj', 'peggy'],
            #     'bob': ['peggy'],
            #     'claire': ['thom', 'jonny'],
            #     'anuj': [],
            #     'peggy': [],
            #     'thom': [],
            #     'jonny': []
            # }
            graph = {}
            graph['you'] = ['alice', 'bob', 'claire']
            graph['alice'] = ['anuj', 'peggy']
            graph['bob'] = ['peggy']
            graph['claire'] = ['thom', 'jonny']
            graph['anuj'] = []
            graph['peggy'] = []
            graph['thom'] = []
            graph['jonny'] = []

        广度优先搜索代码：
            from collections import deque

            def person_is_seller(name):
                return name[-1] == 'm'

            def search(name):
                search_queue = deque()
                search_queue += graph[name]
                # 处理过的节点
                searched = []

                while search_queue:
                    person = search_queue.popleft()
                    if person not in searched:
                        if person_is_seller(person):
                            print('{} is a mango seller!'.format(person))
                            return True
                        else:
                            search_queue += graph[person]
                            searched.append(person)

                return False

            search('you')

    小结：
        广度优先搜索指出是否有从 A 到 B 的路径。
        如果有，广度优先搜索将找出最短路径。
        面临类似于寻找最短路径的问题时，可尝试使用图来建立模型，再使用广度优先搜索来解决问题。
        有向图中的边为箭头，箭头的方向指定了关系的方向，例如 rama --> adit 表示 rama 欠 adit 钱。
        无向图中的边不带箭头，其中的关系是双向的，例如，ross -- rachel 表示 ross 与 rachel 约会，而 rachel 也与 roos 约会。
        队列是先进先出（FIFO）的。
        栈是后进先出（LIFO）的。
        你需要按加入顺序检查搜索列表中的人，否则找到的就不是最短路径，因此搜索列表必须是队列。
        对于检查过的人，务必不要再去检查，否则可能导致无限循环。


第 7 章（狄克斯特拉算法）：
    狄克斯特拉算法
        狄克斯特拉算法用于每条边都有关联数字的图，这些数字称为权重。
            带权重的图称为：加权图
            不带权重的图称为：非加权图

            计算非加权图中的最短路径，使用 “广度优先搜索”，找出的是段数最少的路径。
            计算加权图中的最短路径，可使用 “狄克斯特拉算法”，找出最快的路径。
            如果有负权边，就不能使用狄克斯特拉算法，应该使用 “贝尔曼-福德算法”
                计算两点或两人之间的最短路径，最短路径指的并不一定是物理距离，也可能是让某种度量指标最小。

        狄克斯特拉算法只适用于 有向无环图。

    狄克斯特拉算法的 4 个步骤
        （1）找出 “最便宜” 的节点，也就是可在最短时间内前往的节点。
        （2）计算经该节点前往其各个邻居的开销，如果开销比原先的小，则更新其开销
            （开销 = 起点到该节点的开销 + 该节点到其邻居的开销）
        （3）重复上面的两个步骤
                a、再次执行第一步
                    找出“次便宜节点”
                b、再次执行第二步
                    更新经“次便宜节点”到各个邻居的开销（保留最小的开销）
                c、直到对图中的每个节点都重复过了上面的两个步骤
        （5）计算最终路径

    代码示例：
        准备工作：
            # 图的结构
            graph = {
                'start': {
                    'a': 6,
                    'b': 2
                },
                'a': {
                    'fin': 1
                },
                'b': {
                    'a': 3,
                    'fin': 5
                },
                'fin': {}
            }

            # 每一个节点的开销表：从起点出发前往该节点需要多长时间
            costs = {
                'a': 6,
                'b': 2,
                'fin': float('inf')
            }

            # 存储父节点的散列表
            parents = {
                'a': 'start',
                'b': 'start',
                'fin': None
            }

            # 记录处理过的节点
            processed = []

            def find_lowest_cost_node(costs):
                lowest_cost = float('inf')
                lowest_cost_node = None
                for node in costs:
                    cost = costs[node]
                    if costs < lowest_cost and node not in processed:
                        lowest_cost = cost
                        lowest_cost_node = node
                return lowest_cost_node

            # 狄克斯特拉算法
            # 在未处理的节点找出开销最小的节点
            node = find_lowest_cost_node(costs)
            while node is not None:
                cost = costs[node]
                neighbors = graph[node]
                for n in neighbors.keys():
                    new_cost = cost + neighbors[n]
                    if costs[n] > new_cost:
                        costs[n] = new_cost
                        parents[n] = node
                processed.append(node)
                node = find_lowest_cost_node(costs)

    小结：
        广度优先搜索用于在非加权图中查找最短路径
        狄克斯特拉算法用于加权图中查找最短路径
        仅当权重为正时狄克斯特拉算法才管用
        如果图中包含负权边，请使用贝尔曼-福德算法


第 8 章（贪婪算法）：
    贪心算法（英语：greedy algorithm），又称贪婪算法，是一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望最后堆叠出的结果是最好或最优的算法。
            （贪婪算法所得到的结果不一定是最优的结果(有时候会是最优解)，但是都是相对近似(接近)最优解的结果）
        优点：简单，高效，省去了为了找最优解可能需要穷举操作，通常作为其它算法的辅助算法来使用。
        缺点：不从总体上考虑其它可能情况，每次选取局部最优解，不再进行回溯处理，所以很少情况下得到最优解。
        案例：教室调度问题、背包问题、集合覆盖问题、旅行商问题

    近似算法：
        在获得精确解需要的时间太长时，可使用近似算法。
        贪婪算法易于实现、运行速度快，是不错的近似算法。

        一种 近似算法 的例子：
            （1）选出这样一个广播台，即它覆盖了最多的未覆盖的州。即便这个广播台覆盖了一些已覆盖的州，也没有关系。
            （2）重复第一步，直到覆盖了所有的州。

        判断近似算法优劣的标准如下：
            速度有多快
            得到的近似解与最优解的接近程度

    集合覆盖问题
        定义：
            给定全集 {U}，以及一个包含n个集合且这n个集合的并集为全集的集合{S}。
            集合覆盖问题要找到{S}的一个最小的子集，使得他们的并集等于全集。

            例如{U} = {1, 2, 3, 4, 5}，{S}={{1, 2, 3}, {2, 4}, {3, 4}, {4, 5}}，虽然{S}中所有元素的并集是{U}，
                但是我们可以找到{S}的一个子集{{1, 2, 3}, {4, 5}}，我们称其为一个集合覆盖。

        # 要覆盖的州
        states_needed = set(['mt', 'wa', 'or', 'id', 'nv', 'ut', 'ca', 'az'])

        # 可供选择的广播台清单 键：广播台的名称；值：广播台覆盖的州
        stations = {
            'kone': set(['id', 'nv', 'ut']),
            'ktwo': set(['wa', 'id', 'mt']),
            'kthree': set(['or', 'nv', 'ca']),
            'kfour': set(['nv', 'ut']),
            'kfive': set(['ca', 'az'])
        }

        # 最终选择的广播台
        final_stations = set()

        while states_needed:
            # 覆盖了最多的未覆盖州的广播台
            best_station = None

            # 去除掉已覆盖的州后，该广播台覆盖的所有未覆盖的州
            states_covered = set()
            # for 循环迭代每个广播台，并确定它是否是最佳的广播台
            for station, states_for_station in stations.items():
                covered = states_needed & states_for_station
                if len(covered) > len(states_covered):
                    best_station = station
                    states_covered = covered

            states_needed -= states_covered
            final_stations.add(best_station)

    NP 完全问题
        NP 完全问题的简单定义是：以难解著称的问题，如旅行商问题和集合覆盖问题
            就像集合覆盖问题一样，你需要计算所有的解，并从中选择优的解。NP 完全问题以计算量大无法求得最优解而著称，
            贪心策略是解决 NP 完全问题一个很重要且有效的方法。它也许不能得到最优解，但是可以得到最接近最优解的结果。

        NP 完全问题的识别：
            元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢
            涉及“所有组合”的问题通常是 NP 完全问题
            不能将问题分成小问题，必须考虑各种可能性的情况。这可能是 NP 完全问题
            如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是 NP 完全问题
            如果问题涉及集合（如广播台集合）且难以解决，它可能就是 NP 完全问题
            如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是 NP 完全问题

    小结
        贪婪算法寻找局部最优解，企图以这种方式获得全局最优解。
        对于 NP 完全问题，还没有找到快速解决方案。
        面临 NP 完全问题时，最佳的做法是使用近似算法。
        贪婪算法易于实现、运行速度快，是不错的近似算法。


第 9 章（动态规划）：
    动态规划算法：
        动态规划将问题分解成小问题，然后从小问题着手，先解决子问题，再逐步解决大问题。
        动态规划功能强大，它能够解决子问题并使用这些子问题的答案来解决大问题。但仅当每个子问题都是离散的，即不依赖与其他子问题时，动态规划才管用。

    问题实例：
        背包问题
            解法：贪婪算法（得到近似解，可能不是最优解）、穷举法（最优解）、动态规划（最优解）

            在第8章，学习了如何找到近似解，这接近最优解，但可能不是最优解。如何找到最优解呢？
                使用动态规划

            设计问题的动态规划解决方案：（合并两个子问题的解来得到更大问题的解）
                a、每个动态规划算法都从一个网格表开始，画一个网格表
                b、根据公式来计算每一个单元格的价值，每一个单元格都是一个子问题，网格填满后，就能找到问题的答案了
                    公式：
                        i: 行    j: 列
                        cell[i][j] = max( ( 上一个单元格的值--即cell[i-1][j] ) VS ( 当前商品的价值 + 剩余空间的价值--cell[i-1][j-当前商品的重量] ) )
            启示：
                动态规划可帮助你在给定约束条件下找到最优解。在背包问题中，你必须在背包容量给定的情况下，偷到价值最高的商品。
                在问题可分解为彼此独立且离散的子问题时，就可使用动态规划来解决

        最长公共子串
            伪代码：
                if word_a[i] == word_b[j]:
                    cell[i][j] = cell[i-1][j-1] + 1
                else:
                    cell[i][j] = 0

        最长公共子序列
            伪代码：
                if word_a[i] == word_b[j]:
                    cell[i][j] = cell[i-1][j-1] + 1
                else:
                    cell[i][j] = max(cell[i-1][j], cell[i][j-1])

    设计出动态规划解决方案的小贴士：
        每种动态规划解决方案都涉及网格。
        单元格中的值通常就是你要优化的值。在前面的背包问题中，单元格的值为商品的价值。
        每个单元格都是一个子问题，因此你应考虑如何将问题分成子问题，这有助于你找出网格中的坐标轴。

    动态规划步骤：
        a、绘制网格表：
            单元格中的值是什么？
            如何将这个问题划分为子问题？
            网格的坐标轴是什么？
        b、根据公式填充网格
            填充该网格的每个单元格时，该使用什么样的公式呢？
                去填充，去尝试然后得出公式；有些算法并非精确地解决步骤，而只是帮助你理清思路的框架。

    动态规划的实际应用：
        1）生物学家根据最长公共序列来确定 DNA 链的相似性，进而判断两种动物或疾病有多相似。最长公共序列还被用来寻找多发性硬化症治疗方案。
        2）你使用过诸如 git diff 等命令吗？它们指出两个文件的差异，也是使用动态规划实现的。
        3）前面讨论了字符串的相似程度。编辑距离 指出了两个字符串的相似程度，也是使用动态规划计算得到的。
            编辑距离算法的用途很多，从拼写检查到判断用户上传的资料是否是盗版，都在其中。
        4）你使用过诸如 Microsoft Word 等具有断字功能的应用程序吗？它们如何确定在什么地方断字以确保行长一致呢？使用动态规划！

    小结：
        需要在给定约束条件下优化某种指标时，动态规划很有用。
        问题可分解为离散子问题时，可使用动态规划来解决。
        每种动态规划解决方案都涉及网格。
        单元格中的值通常就是你要优化的值。
        每个单元格都是一个子问题，因此你需要考虑如何将问题分解为子问题。
        没有放之四海皆准的计算动态规划解决方案的公式。


第 10 章（K最近邻算法）：
    K-近邻算法是一种用于 分类 和 回归 的非参数统计方法。在这两种情况下，输入包含特征空间（Feature Space）中的 K 个最接近的训练样本。
        分类
            在 K-NN 分类中，输出是一个分类族群。一个对象的分类是由其邻居的“多数表决”确定的，
            k 个最近邻居（k为正整数，通常较小）中最常见的分类决定了赋予该对象的类别。若 k = 1，则该对象的类别直接由最近的一个节点赋予。
        回归
            在 K-NN 回归中，输出是该对象的属性值。该值是其 k 个最近邻居的值的平均值。

    K-近邻算法的核心思想：
        来了一个新的输入实例，算出该实例与每一个训练点的距离（这里的复杂度为O(n)），然后找到前 K 个，这 K 个哪个类别数最多，我们就判断新的输入实例就是哪类！（类似于现实生活中少数服从多数的思想）

    算法的原理：
        1、K 值的选定
            K 值如何选定？K 为多少效果最好呢？
                一个普遍的做法是利用进化算法优化功能扩展，还有一种较普遍的方法是利用训练样本的互信息进行选择特征。
                K 值的选取，既不能太大，也不能太小，何值为最好，需要实验调整参数确定。一般 K 的取值不超过 20，上限是 n 的开方。

        2、算出该输入实例与每一个训练实例的距离，找到离“输入实例”最近的 K 个训练实例
            “输入示例”和近邻之间的距离又是如何来判断的？
                毕达哥拉斯公式，也称为欧式距离或欧几里得距离
                为了保证每个特征同等重要性，需要对每个特征进行归一化

        3、判断哪个类别最多，将“输入实例”归属到这个最多的类别中

    机器学习简介
        （1）训练：浏览大量的示例并提取特征
        （2）遇到输入的示例时，提取该示例的特征，再找出结果

    小结：
        KNN 用于分类和回归，需要考虑最近的邻居。
        分类就是编组。
        回归就是预测结果（求 K 个最近邻实例的值的平均值）。
        特征抽取意味着将物品（如水果或用户）转换为一系列可比较的数字。
        能否挑选合适的特征事关 KNN 算法的成败。
